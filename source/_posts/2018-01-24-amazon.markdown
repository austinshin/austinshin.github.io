---
layout: post
title: "amazon"
date: 2018-01-24 16:42:45 -0800
comments: true
categories:
---
Should I use Postgres or Mongo or MySQL

Should I use a giant big table or should I use many different entries

Should I use graphQL?

Listings Endpoints
  - (GET) content query for data  -> returns an array of listing objects
  - (GET) collab query for data -> returns an array of listing objects

<!-- more -->


Using Redis:
Some questions I asked myself while thinking about and hearing about redis are...
What is the point of Redis?
What is caching?
What does it mean to store it in memory?
What makes it so much faster than storing it in a MYSQL or NOSQL database?
What are the tradeoffs of storing it in cache?
How does it work?
How can I use it properly?
How can I optimize it even more?

As you increase database size, so does your memory size.

redis-server
redis-cli
FLUSHDB

Using Neo4J:
$ neo4j-client -u neo4j localhost
pw: 123
localhost:7474

graph databases are super cool and efficient.
look at the walmart case studies
basically worked on learning about cyphers and setting up data

tomorrow is going to be about trying to figure out how optimization and querying 10million data points.

--
important queries:
" FOR GETTING ALL RELATIONSHIPS "
MATCH (a:USER)-[relatedTo]-(b) RETURN a.name, b.name, Type(relatedTo), relatedTo;

" FOR GETTING RECOMMENDED LIST FOR A SPECIFIC USER ID BASED ON WHAT OTHER USERS HAVE PURCHASED.
```
"MATCH (a:USER {user_id:'59185'})-[:RELATION]->(m)<-[:RELATION]-(product),(product)-[:RELATION]->(m2) RETURN m2.name AS Recommended, count(*) AS Strength ORDER BY Strength DESC LIMIT 5;
```


some things i've learned:
data partition into different files.
csv is faster than json in neo4j for whatever resaon.

CREATE INDEX ON :Label(name);

USING PERIODIC COMMIT 500
LOAD CSV WITH HEADERS FROM "file:///events1.csv" as input
MATCH (user:USER  {user_id: input.user_id}), (product:PRODUCT {product_id: input.product_id})
CREATE (user)-[:RELATION { type: input.event_type }]->(product);

MATCH (n:Label {name: 'Kadin Mitchell'}),
(n)-[rel:RELATION]->(follower)
where rel.type = 'click'
return n, follower;

MATCH (:USER {name: 'Kadin Mitchell'})-[r]-()
RETURN r

MATCH (n:Label {name: 'b'}),
(n)-[rel:RELATION]->(follower)
where rel.type = 'FOLLOWS'
return n, follower

append to file for creating a new one... (look this up)

Dokku
EC2
Docker
MOCHA CHAI HTTP REQUESTS (TESTS)

feb 1:
https://gist.github.com/austinshin/7883fe17f990fbd69425ba7fe0e2e525
-read up on ec2/aws
-docker
-set up endpoints
-set up integration between redis (caching) and neo4j
-indexing and constraints (understand what it does in neo4j)

things to work on:
- set up redis fetch fake request
- do a siege test on each of the endpoints.
- upload to docker and try to optimize.
-

If our client is requesting something for live time data do we need to have a SQS / message bus system set up to handle it one by one?
my guess is no!

QUERY SYSTEM DATA WITH ONLY DATABASE:
https://puu.sh/zfpbl/066bf7d7cb.png
need to add "write to product" and "write to user"?
 and "create a relationship?"
 can these just be the same thigns over and over again so we can delete it ?


i was recreating a clone amazon web service to answer a certain business question.
add some bs about mocha tests?
I had to generate 10 million data points for my historical dataset...
made sure to test incrementally
to make sure everything works
blah blah
describe  a time when you discovered a small problem eraly on. whatd you do to prevent it from becoming a large rproblem

store in redis as {user_id: recommendedList}?
or... store as index = user_id : recommendedList?


takes about 5 seconds to query and cache 10 results
takes about 12 seconds to query and cache 100 reuslts
takes about 30 seconds to query and cache 1000 results

takes 3ms to query cached recommendations.
takes 300ms to query neo4j to calculate a recommendation.

https://puu.sh/zg611/931730d3d1.png


TODO:
1. change content filter method to compare to products.
2. change redis key:value schema (to be {user_id: [recommended list]})
3. add a cronjob to update every so often...
4. add logic to "check if user/product exists. if they don't, MERGE them into neo4j, create a relationship" (use a queue system or something to do this? not sure...)
^ should be able to handle a good amount of new users.

5. start working on docker and getting that set up i suppose.

Feb 5:
refactored redis to use hash table instead of arrays~ because I needed to keep track of userid
added mocha and chai testing for TDD (there's a nice article about BDD, unit tests, and TDD)
created video for thesis midpoint project
https://joshldavis.com/2013/05/27/difference-between-tdd-and-bdd/

tomorrow's goals:
new relic
docker
cronjob endpoints to other two services.
read up on 10k rps...
set up a messagebus queue if i need it?
unit test endpoints

deployment to EC2

work on collaborative recommendation algorithm


-------------
ec2 related stuff:
https://medium.com/@andrewcbass/install-redis-v3-2-on-aws-ec2-instance-93259d40a3ce
ssh -i ~/.ssh/redis.pem ec2-user@34.209.95.160

docker stuff

1. make a dockerfile
2. add all the commands
3. docker build -t austinshin/thesis .
4. docker run -d -p 49160:3000 -v $(pwd):/src/app --name thesis austinshin/thesis
5. to remove...
6. stop the docker container
7. docker rm containername
8. docker rmi imagename
CALL dbms.changePassword('123');


docker exec -t -i container_name /bin/bash

docker-machine ls
docker-machine start

docker exec -t -i recommendationservice_neo4j_1 /bin/bash
eval "$(docker-machine env default)"

----------------------------------
upload to ec2 now

load balancing
ECS
figure that hsit out

set up queue and then have it point to multiple databases.

ecs-cli up
ecs-cli up --keypair app --capability-iam --size 3 --instance-type t2.medium --force
ecs-cli compose --file docker-compose.yml up
change security group to allow TCP 22 (with ur ip so you can ssh in)

ssh -i ~/desktop/app.pem ec2-user@54.215.227.138
sudo yum update
sudo yum install -y docker
sudo service docker start
sudo usermod -a -G docker ec2-user
docker info


ecs-cli down
